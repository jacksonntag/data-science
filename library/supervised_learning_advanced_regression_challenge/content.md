---
title: Challenge
author: Thinkful
team: grading
time: 90
---

Now that you have two new regression methods at your fingertips, it's time to give them a spin.  In fact, for this challenge, let's put them together!  Pick a dataset of your choice with a binary outcome and the potential for at least 15 features.  If you're drawing a blank, the [crime rates in 2013](https://ucr.fbi.gov/crime-in-the-u.s/2013/crime-in-the-u.s.-2013/tables/table-8/table_8_offenses_known_to_law_enforcement_by_state_by_city_2013.xls/view) dataset has a lot of variables that could be made into a modelable binary outcome.  

Engineer your features, then create three models.  Each model will be run on a training set and a test-set (or multiple test-sets, if you take a folds approach).  The models should be:

 1. Vanilla logistic regression
 2. Ridge logistic regression
 3. Lasso logistic regression

If you're stuck on how to begin combining your two new modeling skills, here's a hint: the [SKlearn LogisticRegression method](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) has a "penalty" argument that takes either `'l1'` or `'l2'` as a value.

In your report, evaluate all three models and decide on your best. Be clear about the decisions you made that led to these models (feature selection, regularization parameter selection, model evaluation criteria) and why you think that particular model is the best of the three. Also reflect on the strengths and limitations of regression as a modeling approach. Were there things you couldn't do but you wish you could have done?

Record your work and reflections in a notebook to discuss with your mentor.

