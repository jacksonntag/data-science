---
title: Question design
author: Thinkful
team: grading
time: 60
uuid: 485299b7-3854-4b82-b4c8-ad9ff378efa2
---

A survey is only as good as the questions it contains.  Considerations in question design include question type, question wording, and how to deal with non-response.

## Question Types

__Multiple choice/choose one__ – Options are typically mutually exclusive

_What is your favorite color?_
 * Green
 * Blue
 * I don't know
 * Other

__Multiple choice/choose as many as apply__

_Mark which cheeses you like to eat:_
 * Camembert
 * Cheddar
 * Wensleydale
 * Red Leicestershire
 * Other

__Write-in / Free response__

_Please tell us your opinion of the Ministry of Silly Walks._

__Yes / No questions__ – These are often used to filter out people who don't fit your population of interest.

_Are you here to argue?_ 
 * Yes
 * No

__Rating scale__, with word or numeric anchors at each end.

_How dead is this parrot?_
0 (Only sleeping) 1 2 3 4 5 6 (Pining for the Fjords)

__Ranking__

_Please rate the following items in terms of how frightening they are, with 1 being the most frightening and 4 being the least frightening.  Use each rating number only once._

 * \_\_\_Tim the Enchanter
 * \_\_\_The Killer Rabbit of Caerbannog
 * \_\_\_Brave Sir Robin
 * \_\_\_A newt

__Constant sum__

_Describe how you spend your time by dividing 100 points among the following list of items.  More points in an item indicates that you spend a higher percentage of your time in that task.  Your points must total 100._
 
 * \_\_\_Riding forth from Camelot
 * \_\_\_Being killed in nasty ways
 * \_\_\_Running away
 * \_\_\_Being brave
 * \_\_\_Arguing with minstrels

## DRILL: Question Design

For each of the following, indicate the best question type to use and why.

 * Age
 * Gender
 * Income
 * Opinions about dish soap
 * Brand of dish soap used
 * Preference for dish soap brand (Cleany, Sudsy, DeGreaser, Pinesoft)
 * Positive vs negative feelings about dish soap

## Flawed Questions

Sometimes a question is phrased in a way that encourages a particular answer.  If the goal of your survey is to discover what your respondents really think, these questions need to be weeded out!

Sometimes the problem is from the *framing*.  Consider the following two questions:

Q1. Should we allow dancing on Sundays?
Q2. Should we forbid dancing on Sundays?

Logically, if you randomly gave question 1 to some people and question 2 to others, the percentage of people giving pro-dancing responses should be the same in both groups.  In reality, however, more people say they are anti-dancing in response to question 1 than in response to question 2.  This is because the way question 2 is phrased implies that we currently allow dancing, and are considering forbidding it – which would be a loss of the right to dance.  In contrast, question 1 implies that we currently forbid dancing, and are considering allowing it – a potential gain.  People are much more comfortable refusing a gain (dancing is not and should not be allowed) than embracing a loss (dancing is allowed but should not be allowed).

A third way to ask the question contains no assumptions about the current state of dancing rights, and is thus unbiased:

Q3. What is your opinion of dancing on Sundays?

 * Should be allowed
 * Should be forbidden

Sometimes a question that appears to be one question actually contains two questions, with the answer to the first question assumed.  These so-called **loaded** questions can cause massive confusion in your data.  For example, take the question "Are you still working at McDonalds?" There's no way to answer this question accurately if you've never actually worked there: 'Yes' would imply that you have and still do work there, while "No" implies that you worked at McDonalds at one time.  

A better way to avoid loaded questions is to make the assumption into its own explicit question:

 * Have you ever worked at McDonalds? Yes/No
 * If yes, are you still working at McDonalds? Yes/No

Because our own assumptions can be difficult to spot, it is always a good idea to have a few other people read over your survey questions to check them.  At best, loaded questions make it hard to interpret responses.  At worst, a loaded question can be so offensive that you lose a customer entirely:  Imagine being asked "How often do you beat your dog?"" and the least frequent option is "0 to 2 times a week"!  


## DRILL: Fix the flaw

Here is a [link](https://action.donaldjtrump.com/mainstream-media-accountability-survey/) to a Mainstream Media Accountability Survey sent to the public by the Trump Administration in February 2017.  Read over the survey and select five questions you believe can be improved.  Describe the flaw you see and write an improved version of the question. For example, if the original question is: 
"Americans are not fully aware just how much waste there is in the federal government." 
Yes
No
No Opinion 

The flaw is that this is a loaded question that presupposes the respondent agrees that there is waste in the federal government.  To ask this question in a less-biased way, it would need to be converted to two questions:

 * Select the option that describes your opinion of how the federal government handles money:
   * Wastefully
   * Efficiently
   * No Opinion

IF they selected a, then:

 * Describe American public opinion about government waste.
   * 0 (Unaware) 1 2 (Somewhat Aware) 3 4 (Fully Aware)

For each revised question, your version should attempt to get an unbiased picture of the respondent's opinion on the issue.  Share your reasoning with your mentor.

## No answer

People are tricky beasts – no matter how hard you try, you're likely to have one or two questions where none of the response options are a good fit to some of your respondents.  In other cases, you may be asking questions about sensitive subjects like income or sexual orientation, which people might want to skip.  What do you do?

Options depend on whether your survey is being administered online, in real time by a survey administrator, or in pencil/paper.  Sometimes you can require that people give a response to each question before they can move on to the next question – this is obviously impossible for pencil/paper situations.  The forced response option is risky: People may be offended or confused and quit the survey altogether, or they may choose an option at random just to move on to the next question.  

You could provide a 'choose not to respond' option for each question, or allow people to skip questions they don't want to answer.  This means that all answers reflect information given willingly.  Allowing people to skip questions introduces the possibility of bias – gay people are less likely to respond to your sexual orientation question than straight people, leading you to underestimate how many of your respondents are gay.  In addition, people may use the skip option to avoid questions that are long or complex, or to avoid having to think too hard about their opinions.  On the other hand, the choice to skip is, itself, an answer – just not the most informative one.

For multiple-choice questions, you could include an 'Other' option that people can choose if none of the available options apply.  You would then ask the person to write in what 'Other' category they fall into.  Write-in data of any kind is complex (people misspell, they write nonsense, they give answers that are hard to understand in other ways) but it does avoid the problem of forcing people to choose an answer that doesn't actually apply to them.

Ultimately, the strategy you choose depends on the types of questions you ask, how concerned you are about the possibility of bias, and how important it is to avoid alienating your respondents.

