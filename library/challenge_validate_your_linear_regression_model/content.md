---
title: 'Challenge: validate your linear regression model'
author: Thinkful
team: grading
time: 90
uuid: ce6b39f9-7b95-47b3-b42c-099eedd39b8f
---

## Validating regression models for prediction

Statistical tests are useful for making sure a model is a good fit to the test data, and that all the features are useful to the model.  However, to make sure a model has good predictive validity for new data, it is necessary to assess the performance of the model on new datasets.

The procedure is the same as what you learned in the Naive Bayes lesson â€“ the holdout method and cross-validation method are both available.  You've already had experience writing code to run these kinds of validation models for Naive Bayes: now you can try it again with linear regression.  In this case, your goal is to achieve a model with a consistent R<sup>2</sup> and only statistically significant parameters across multiple samples.

We'll use the property crime model you've been working on with, based on the FBI:UCR data. Since your model formulation to date has used the entire New York State 2013 dataset, you'll need to validate it using some of the other crime datasets available at the FBI:UCR website.  Options include [other states crime rates in 2013](https://ucr.fbi.gov/crime-in-the-u.s/2013/crime-in-the-u.s.-2013/tables/table-8/table_8_offenses_known_to_law_enforcement_by_state_by_city_2013.xls/view) or [crime rates in New York State in other years](https://ucr.fbi.gov/crime-in-the-u.s/2014/crime-in-the-u.s.-2014/tables/table-8/table-8-by-state/Table_8_Offenses_Known_to_Law_Enforcement_by_New_York_by_City_2014.xls) or a combination of these.

## Iterate

Based on the results of your validation test, create a revised model, and then test both old and new models on a new holdout or set of folds.

Include your model(s) and a brief writeup of the reasoning behind the validation method you chose and the changes you made to submit and review with your mentor.

