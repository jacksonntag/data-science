---
title: Program overview
author: Thinkful
team: grading
time: 30
---

Hiring managers have a high bar for professional work, so we set our standards accordingly. We review each stage of your work with rigor, providing critical feedback along the way. As a result, Thinkful graduates land the jobs they want and can perform on day 1.

Let's have a look at some of the central pillars of your experience in this program:

## Goals

Throughout your learning journey, many Thinkful team members will approve goals as you work your way through the curriculum - from Student Success, Program Managers, Mentors, as well as Career Services. It is worth noting here; it’s CRUCIAL for you to know that you need to rely on mentors for the majority of your technical-specific goals and project feedback. 

### Goal Approval

If you’re ever concerned about your pacing, review all the goals in your Goals tab in your dashboard as well as your graduation plan.

Thinkful’s Data Science program is a self-paced study program which means that we do not enforce a strict deadline or have punitive actions for delays. This is not a traditional school with fixed deadlines for a classroom, every student is on their own personal learning journey and must be accountable to manage their time responsibly. 

That being said if you are the sort of person who needs to see dates to help with your pacing, let your Program Manager know and they can assist you with time management tips and tricks. 

## Submitting work

Many of the curriculum checkpoints will include assignments for you to complete in order to practice or demonstrate your mastery of the new concepts and skills you're learning.

When you're asked to submit assets like Jupyter notebooks or other code assets, you'll need to store these at a location that makes sense (most likely GitHub) and provide a **publicly-accessible link** to these assets, otherwise Thinkful team members won't be able to view it.


## Curriculum 

Let’s talk a bit about the curriculum. Here' we'll provide an overview of the curriculum modules that you'll encounter in the trial program, as well as the full list that you'll encounter if you enroll in the full Data Science bootcamp. Please note that this is simply a bird’s eye view of the format; if you want a more thorough breakdown or have additional questions or concerns make sure to bring it up with your Program Manager. 

Here's a breakdown of the curriculum modules that make up the trial program

- *Orientation* — This module (which you're currently looking at!) gets you up to speed on the details of the program. We describe all the people, services and resources that are here to help you succeed.
- *Careers: Get to know the job landscape* — Learn about the technical landscape and what to expect from our Careers team. Youll also get a head-start on finding jobs and understand the types of roles to target.
- *Programming in Python* - Explore programming fundamentals in Python. You'll learn the building blocks of programming in Python that will allow you to solve all problems big and small as a data scientist.
- *Basic statistics and probability with Python* — Get to know the Python data science toolkit consisting of Python + Jupyter Notebooks + Pandas + SciPy + Numpy + Matplotlib as we explore how to do basic statistical analysis in the initial exploratory phase of a project. At the end of this module, you'll complete your first capstone project.

If you decide to continue on in the full bootcamp, these modules follow:

- *Careers: Mastering Networking and Meetups* — Learn how to speak about yourself as a data scientist, find and attend relevant events, and conduct an informational interview with a seasoned data scientist.
- *SQL for data scientists* — In this module, you'll master one of the core tools in the data science toolkit: SQL. You'll learn how to connect to databases and read and write data.
- *Deeper into data visualization and exploration* — Creating clear, clean, easy-to-understand visuals is a critical skill. Data cleaning is closely intertwined with data visualization. Good plots help us identify problems in the data that could interfere with getting accurate results. In this module, we'll review different types of problems you may encounter and some methods of dealing with problems after you find them.
- *Experimental design and A/B testing* — Experimental design can be a powerful tool in your data science arsenal, and like all powerful tools, it needs to be handled the right way. In this module, we'll discuss A/B testing and how to evaluate a good experiment, writing a research proposal, and analytical techniques to use when an experiment yields non-normal data.
- *Careers: Applying, interviewing, getting, and negotiating jobs* — In this module, you'll learn everything you need to know to prepare for, secure, and excel in job interviews.
- *Supervised learning: model preparation* — In this module, we'll begin to explore supervised learning, which is one of the main branches of the broader field of machine learning. Here, we'll explore the preliminary steps in any machine learning project: formulating a research question that can be modeled, data exploration from a modeling perspective, and feature engineering and selection.
- *Supervised learning: solving classification problems* — In this module, you'll learn how to create classification models, which output labels or categories. When you need a model that can do things like label something as spam/not spam, high risk of default / low risk, etc., you're dealing with classification.
- *Supervised learning: solving regression problems* — In this module, you'll learn how to create models that solve regression problems, which is when given a set of inputs, you want to produce one or more scalar numeric values as an output.
- *Supervised learning: similarity models* — In this module, we'll introduce a new class of models: similarity models. These are exactly what they sound like: learning through similarity. We'll cover similarity models as an overarching concept as well as their classic example: K-Nearest Neighbors.
- *Supervised learning: random forest models* — In this module we'll introduce some of the most common and powerful models of supervised learning: the Decision Tree and the Random Forest. Random Forest will be your first example of an ensemble model, a new modeling technique we'll return to throughout the course. 
- *Supervised learning: support vector machines* — In this module, we'll introduce a powerful classifier and regression technique: support vector machines (SVMs). We'll cover the original classifier implementation as well as how that can be transformed to create a similar model for regression.
- *Supervised learning: boosting models* — In this module we'll introduce boosting, a type of ensemble modeling very popular for its flexibility and predictive power. Many a Kaggle competition has been won using boosting!
- *Careers: professional branding* — The first step in getting ready for applying to jobs is to rebrand yourself as a data scientist. Through our lessons on professional branding, you'll learn how to create a successful resume, LinkedIn profile, and cover letter. 
- *Unsupervised learning: an overview* — In this short module, you'll get a high-level introduction to what unsupervised learning is all about.
- *Unsupervised learning: clustering* — In this module, we'll explore one of the most common unsupervised learning techniques: clustering. This mdethod is about grouping together (or clustering) similar datapoints.
- *Unsupervised learning: neural networks* — Neural Networks are one of the most popular and impactful branches of machine learning today. This is the very bleeding edge of data science, but it has historical roots. In this module we'll explore: the perceptron model, multi-level perceptrons, and neural network structure.
- *Other topics: Algorithms and data structures* — In this module, we'll spend some time explicitly talking about algorithms and data structures.
- *Other topics: web scraping* — In this module, you'll learn all about web scraping. Web scraping (or data scraping) is the process of programmatically extracting data from a website and saving it to a file or database. By gaining the ability to scrape web data, you gain massively expand the data you have available at your fingertips as a data scientist.
- *Other topics: big data* — As a data scientist you’ll be expected to be able to ‘speak’ big data. In this module, you'll learn how to work with big data.
- *Other topics: survey design* — In this module, we'll explore the intricacies of designing robust research surveys.
- *Other topics: Advanced Experimentation* — In this module, we'll return to the topic of experimental design, which we discussed much earlier in the bootcamp. You'll learn about some alternatives to T-tests, which will expand your ability to make quantitative comparisons.
- *Specializations: At this point in the program, you will choose to work through one of the following specialization curriculum modules (although you'll have access to all of them):
  * *Time Series Analysis* — This specialization covers some of the fundamental ways data scientists can deal with time. We'll cover some theory about processes and a concept called stochasticity. Then we'll cover some ways to transform our current tool set, particularly linear modeling, to handle time.
  * *Network Analysis* — When the question of interest is relationships among many things, data scientists turn to network analysis. The goal of this module is to give you enough knowledge to be able to talk with others about basic network analysis concepts and enough experience to decide if you want to pursue networks further.
  * *Data Science for Economics* — In this specialization, we'll explore some of the peculiarities around modeling economic data, combining some classic techniques with contemporary scale.
  * *Natural language processing* — This specialization will get you up to speed on natural language processing (NLP), which is the realm of data science that focuses on teaching computers to 'understand' human verbal communication. 
  * *Data Science for Social Sciences* — This specialization explores one of the core concerns of social science research: how groups change over time. By following a sample of people over time while repeatedly measuring our variables of interest, we can begin to understand how, when, and even why people and societies change.
  * *Tensorflow and Keras* — This specialization will guide you in your first steps learning TensorFlow and Keras, which are amongst the most powerful tools avaialable to implement neural networks.
  * *Biostatistics* — This specialization focuses on biostatistics, also known as bioinformatics, which combines the modeling techniques of data science with the thought patterns of medical science to understand and predict health and disease.
  * *Big Data and Spark* — In this specialization, you'll learn to answer research questions using Spark with large datasets.
